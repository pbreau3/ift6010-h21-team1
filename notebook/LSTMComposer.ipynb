{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMComposer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeMifCZzxfoH"
      },
      "source": [
        "# LSTM Composer\n",
        "\n",
        "Simple Stacked LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZpbDlOciV_b"
      },
      "source": [
        "Some part of the code were taken as is (helper functions), or adapted (train and trainIters) from the pytorch tutorial \"NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\" by Sean Robertson.\n",
        "\n",
        "link: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "556D6dBODBYY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qpvI9JEx9FF"
      },
      "source": [
        "Mount Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeNvBRSqx_Yg",
        "outputId": "e40307f5-3a15-4393-bdfc-b9e7bded63dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mtn6kqVE3Ttk",
        "outputId": "96932916-4e90-414b-eaea-b4907daf0ccf"
      },
      "source": [
        "# mount\n",
        "path_to_project = \"/content/drive/MyDrive/Colab Notebooks/NLP6010/Project6010\" #@param string\n",
        "%cd $path_to_project"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NLP6010/Project6010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_8L1PkweClLC",
        "outputId": "c335aec2-5110-4e11-fcc5-7d08f05227a6"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/NLP6010/Project6010'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUyo0aJBx0oK"
      },
      "source": [
        "Prepare the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCTikhqIxVZT"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def get_sentences(datapath):\n",
        "    # Get a list of tokenized sentences from a corpus\n",
        "    data = []\n",
        "    f = open(datapath, \"r\")\n",
        "    for line in f:\n",
        "        sent = [word for word in line.split(' ') if word is not '\\n']\n",
        "        data.append(sent)\n",
        "    f.close()\n",
        "\n",
        "    return data\n",
        "\n",
        "def build_vocab():\n",
        "    # Build a list with the modified vocabulary of \"Music with Expressivity...\"\n",
        "    # size: 267+1PAD = 268\n",
        "    vocab = []\n",
        "\n",
        "    #0: PAD\n",
        "    vocab.append(\"<PAD>\")\n",
        "\n",
        "    for note in range(128):\n",
        "        vocab.append(\"NOTE_ON<{}>\".format(note))\n",
        "        vocab.append(\"NOTE_OFF<{}>\".format(note))\n",
        "\n",
        "    for tick in [120, 240, 360, 480, 600, 720, 840, 960]:\n",
        "        vocab.append(\"TICKSHIFT<{}>\".format(tick))\n",
        "\n",
        "    for token in [\"<START>\", \"<END>\", \"SILENCE\"]:\n",
        "        vocab.append(token)\n",
        "\n",
        "    return vocab\n",
        "\n",
        "def build_training_batch(datapath):\n",
        "    \"\"\"\n",
        "    Create a one hot encoding for all the input data\n",
        "    \"\"\"\n",
        "    corpus = get_sentences(datapath)\n",
        "    vocab = build_vocab()\n",
        "\n",
        "    #List of indices\n",
        "    vector_seqs = [[vocab.index(tok) for tok in seq] for seq in corpus]\n",
        "\n",
        "    seq_lengths = torch.LongTensor(list(map(len, vector_seqs)))\n",
        "\n",
        "    #Pad the sequences: pad idx==0\n",
        "    seq_tensor = torch.autograd.Variable(torch.zeros((len(vector_seqs), seq_lengths.max()))).long()\n",
        "\n",
        "    for idx, (seq, seqlen) in enumerate(zip(vector_seqs, seq_lengths)):\n",
        "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
        "    #Shape: (B x S)\n",
        "\n",
        "    \"\"\"\n",
        "    #Embed the seqs\n",
        "    embed = nn.Embedding(len(vocab), embed_dim)\n",
        "    embed_seq_tensor = embed(seq_tensor) #Shape: (B x S x Emb)\n",
        "\n",
        "    #Pack seq\n",
        "    packed_input = pack_padded_sequence(embed_seq_tensor, seq_lengths.cpu().numpy(), batch_first=True, enforce_sorted=False)\n",
        "    # packed_input (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes\n",
        "    \"\"\"\n",
        "    #seq_tensor: padded sequences (B x MAX_SEQ_LEN)\n",
        "    #seq_lengths: lens of each seq\n",
        "    #vocab: list of tokens\n",
        "\n",
        "    return seq_tensor, seq_lengths, vocab\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BanSA23GC2PX"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dm7TWxeC3RW"
      },
      "source": [
        "\n",
        "class LSTMcomposer(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size, out_size, n_stack, vocab, embed_dim):\n",
        "        super(LSTMcomposer, self).__init__()\n",
        "        self.in_size = in_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_stack = n_stack\n",
        "        self.out_size = out_size #correspond to 1-hot vector of an event\n",
        "\n",
        "        self.embed = nn.Embedding(len(vocab), embed_dim)\n",
        "        self.lstm = nn.LSTM(in_size, hidden_size, n_stack, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, out_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, seq, seq_len):\n",
        "        #seq_tensor: S_MAX\n",
        "        #seq_lengths: 1\n",
        "        #input: (B, S, F)\n",
        "        #h_0: (B, n_stack, hidden_size) init state for each element in batch\n",
        "        #c_0: (B, n_stack, hidden_size) init cell state for each element in batch\n",
        "        # out, (h_n, c_n) = self.lstm(input, (h_0, c_0))\n",
        "\n",
        "        output = []\n",
        "\n",
        "        h_t = self.initHidden()\n",
        "        c_t = self.initHidden()\n",
        "\n",
        "        embed_seq = self.embed(seq)  # Shape: (S x Emb)\n",
        "        embed_seq = embed_seq.to(device)\n",
        "\n",
        "        for ti in range(seq_len):\n",
        "            out, (h_t, c_t) = self.lstm(embed_seq[ti].unsqueeze(0).unsqueeze(0), (h_t, c_t))\n",
        "            out = self.out(out)\n",
        "            score = self.softmax(out)\n",
        "            output.append(score)\n",
        "\n",
        "        output = torch.stack(output).to(device)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.n_stack, self.hidden_size, device=device)\n",
        "    \n",
        "    def generate(self, start_token, vocab, MAX_LEN=728):\n",
        "      song = []\n",
        "\n",
        "      with torch.no_grad():\n",
        "              h_t = self.initHidden()\n",
        "              c_t = self.initHidden()\n",
        "\n",
        "      curr_idx = start_token.item()\n",
        "      \n",
        "      embed_seq = self.embed(start_token)  # Shape: (1 x Emb)\n",
        "      embed_seq = embed_seq.to(device)\n",
        "\n",
        "      for ti in range(MAX_LEN):\n",
        "          out, (h_t, c_t) = self.lstm(embed_seq.unsqueeze(0), (h_t, c_t))\n",
        "          out = self.out(out)\n",
        "          score = self.softmax(out)\n",
        "\n",
        "          sorted_ids = torch.argsort(score)\n",
        "          # print(sorted_ids.squeeze().cpu().numpy().shape)\n",
        "          for idx in sorted_ids.squeeze().cpu().numpy():\n",
        "            if idx == curr_idx:\n",
        "              pass\n",
        "            else:\n",
        "              song.append(vocab[idx])\n",
        "              curr_idx = idx\n",
        "              break\n",
        "          \n",
        "          nxt_token = torch.LongTensor([idx])\n",
        "          nxt_token = nxt_token.to(device)\n",
        "          nxt_embed = self.embed(nxt_token)\n",
        "\n",
        "          embed_seq = nxt_embed\n",
        "\n",
        "          if song[-1] == '<END>':\n",
        "            break\n",
        "\n",
        "      return song\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6ziRXwP7zku"
      },
      "source": [
        "#Train for 1 epoch\n",
        "def train(lstm, lstm_optim, criterion, seq_tensor, seq_lengths):\n",
        "\n",
        "  S_MAX = seq_tensor.shape[1]\n",
        "  batch_size = seq_tensor.shape[0]\n",
        "  loss = 0\n",
        "\n",
        "  lstm_optim.zero_grad()\n",
        "\n",
        "  #todo: Change to batch size FOR REAL\n",
        "  for ei in range(batch_size):\n",
        "    seq = seq_tensor[ei]\n",
        "    seq_len = seq_lengths[ei]\n",
        "    logits = lstm(seq, seq_len)\n",
        "    logits = logits.squeeze().squeeze()\n",
        "\n",
        "    #Build target: end token have pad as their target\n",
        "    target = np.zeros(seq_len)\n",
        "    labels = seq.cpu().numpy()\n",
        "    target[:(seq_len-1)] = labels[1:seq_len]\n",
        "    target = torch.LongTensor(target)\n",
        "    target = target.to(device)\n",
        "\n",
        "    loss = loss + criterion(logits, target)\n",
        "\n",
        "  loss.backward()\n",
        "  lstm_optim.step()\n",
        "\n",
        "  return loss.item()/ S_MAX"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUjZPXQfCx67"
      },
      "source": [
        "#Helper fcts\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # # this locator puts ticks at regular intervals\n",
        "    # loc = ticker.MultipleLocator(base=0.2)\n",
        "    # ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "def trainItersLSTM(lstm, seq_tensor, seq_lengths, n_iter, print_every=1000, plot_every=100, save_every=2, lr=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0 #reset every print_every\n",
        "    plot_loss_total = 0 #reset every plot_every\n",
        "\n",
        "    lstm_optim = torch.optim.Adam(lstm.parameters(), lr)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1,n_iter+1):\n",
        "        loss = train(lstm, lstm_optim, criterion, seq_tensor, seq_lengths)\n",
        "\n",
        "        print_loss_total = print_loss_total + loss\n",
        "        plot_loss_total = plot_loss_total + loss\n",
        "\n",
        "        if iter % save_every == 0:\n",
        "            torch.save({'epoch': iter,\n",
        "                        'model_state_dict': lstm.state_dict(),\n",
        "                        'optimizer_state_dict': lstm_optim.state_dict(),\n",
        "                        'loss': loss\n",
        "                        }, 'lstm.pth')\n",
        "            print(\"~Saved checkpoint\")\n",
        "\n",
        "        if iter % print_every ==0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iter),\n",
        "                                         iter, iter / n_iter * 100,\n",
        "                                         print_loss_avg))\n",
        "\n",
        "        if iter % plot_every ==0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "\n",
        "\n",
        "    #Save models\n",
        "    torch.save(lstm.state_dict(), \"lstm.pt\")\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "    return 0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7qge5WK7DxWX",
        "outputId": "75c7efd9-e455-41e2-cfe6-2cf794fc0b2e"
      },
      "source": [
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "datapath = r\"corpus.txt\"\n",
        "\n",
        "embed_dim = 400\n",
        "hid_size = 600\n",
        "seq_tensor, seq_lengths, vocab = build_training_batch(datapath)\n",
        "seq_tensor = seq_tensor.to(device)\n",
        "\n",
        "lstm = LSTMcomposer(in_size=embed_dim, hidden_size=hid_size, out_size=len(vocab), n_stack=1, vocab=vocab, embed_dim=embed_dim)\n",
        "lstm.to(device)\n",
        "\n",
        "trainItersLSTM(lstm, seq_tensor, seq_lengths, n_iter=100, print_every=2, plot_every=5, save_every=2, lr=0.01)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~Saved checkpoint\n",
            "4m 24s (- 215m 48s) (2 2%) 1.5369\n",
            "~Saved checkpoint\n",
            "8m 48s (- 211m 23s) (4 4%) 1.3444\n",
            "~Saved checkpoint\n",
            "13m 11s (- 206m 41s) (6 6%) 1.1861\n",
            "~Saved checkpoint\n",
            "17m 33s (- 202m 0s) (8 8%) 0.9869\n",
            "~Saved checkpoint\n",
            "21m 57s (- 197m 35s) (10 10%) 0.8268\n",
            "~Saved checkpoint\n",
            "26m 20s (- 193m 11s) (12 12%) 0.7771\n",
            "~Saved checkpoint\n",
            "30m 44s (- 188m 47s) (14 14%) 0.7203\n",
            "~Saved checkpoint\n",
            "35m 7s (- 184m 24s) (16 16%) 0.6782\n",
            "~Saved checkpoint\n",
            "39m 31s (- 180m 2s) (18 18%) 0.6364\n",
            "~Saved checkpoint\n",
            "43m 54s (- 175m 39s) (20 20%) 0.5977\n",
            "~Saved checkpoint\n",
            "48m 18s (- 171m 15s) (22 22%) 0.5603\n",
            "~Saved checkpoint\n",
            "52m 42s (- 166m 54s) (24 24%) 0.5245\n",
            "~Saved checkpoint\n",
            "57m 5s (- 162m 29s) (26 26%) 0.4923\n",
            "~Saved checkpoint\n",
            "61m 29s (- 158m 6s) (28 28%) 0.4644\n",
            "~Saved checkpoint\n",
            "65m 53s (- 153m 44s) (30 30%) 0.4357\n",
            "~Saved checkpoint\n",
            "70m 17s (- 149m 22s) (32 32%) 0.4127\n",
            "~Saved checkpoint\n",
            "74m 41s (- 144m 59s) (34 34%) 0.3925\n",
            "~Saved checkpoint\n",
            "79m 4s (- 140m 35s) (36 36%) 0.3736\n",
            "~Saved checkpoint\n",
            "83m 28s (- 136m 12s) (38 38%) 0.3551\n",
            "~Saved checkpoint\n",
            "87m 53s (- 131m 49s) (40 40%) 0.3384\n",
            "~Saved checkpoint\n",
            "92m 17s (- 127m 27s) (42 42%) 0.3314\n",
            "~Saved checkpoint\n",
            "96m 41s (- 123m 4s) (44 44%) 0.3197\n",
            "~Saved checkpoint\n",
            "101m 6s (- 118m 41s) (46 46%) 0.3042\n",
            "~Saved checkpoint\n",
            "105m 31s (- 114m 19s) (48 48%) 0.2917\n",
            "~Saved checkpoint\n",
            "109m 55s (- 109m 55s) (50 50%) 0.2784\n",
            "~Saved checkpoint\n",
            "114m 19s (- 105m 32s) (52 52%) 0.2662\n",
            "~Saved checkpoint\n",
            "118m 44s (- 101m 8s) (54 54%) 0.2553\n",
            "~Saved checkpoint\n",
            "123m 8s (- 96m 45s) (56 56%) 0.2434\n",
            "~Saved checkpoint\n",
            "127m 32s (- 92m 21s) (58 57%) 0.2326\n",
            "~Saved checkpoint\n",
            "131m 56s (- 87m 57s) (60 60%) 0.2243\n",
            "~Saved checkpoint\n",
            "136m 19s (- 83m 33s) (62 62%) 0.2290\n",
            "~Saved checkpoint\n",
            "140m 43s (- 79m 9s) (64 64%) 0.2294\n",
            "~Saved checkpoint\n",
            "145m 8s (- 74m 46s) (66 66%) 0.2183\n",
            "~Saved checkpoint\n",
            "149m 34s (- 70m 23s) (68 68%) 0.2058\n",
            "~Saved checkpoint\n",
            "153m 59s (- 65m 59s) (70 70%) 0.1957\n",
            "~Saved checkpoint\n",
            "158m 26s (- 61m 36s) (72 72%) 0.1868\n",
            "~Saved checkpoint\n",
            "162m 53s (- 57m 13s) (74 74%) 0.1773\n",
            "~Saved checkpoint\n",
            "167m 19s (- 52m 50s) (76 76%) 0.1683\n",
            "~Saved checkpoint\n",
            "171m 44s (- 48m 26s) (78 78%) 0.1612\n",
            "~Saved checkpoint\n",
            "176m 8s (- 44m 2s) (80 80%) 0.1642\n",
            "~Saved checkpoint\n",
            "180m 32s (- 39m 37s) (82 82%) 0.1516\n",
            "~Saved checkpoint\n",
            "184m 56s (- 35m 13s) (84 84%) 0.1445\n",
            "~Saved checkpoint\n",
            "189m 21s (- 30m 49s) (86 86%) 0.1367\n",
            "~Saved checkpoint\n",
            "193m 45s (- 26m 25s) (88 88%) 0.1304\n",
            "~Saved checkpoint\n",
            "198m 9s (- 22m 1s) (90 90%) 0.1247\n",
            "~Saved checkpoint\n",
            "202m 33s (- 17m 36s) (92 92%) 0.1252\n",
            "~Saved checkpoint\n",
            "206m 58s (- 13m 12s) (94 94%) 0.1278\n",
            "~Saved checkpoint\n",
            "211m 23s (- 8m 48s) (96 96%) 0.1152\n",
            "~Saved checkpoint\n",
            "215m 46s (- 4m 24s) (98 98%) 0.1081\n",
            "~Saved checkpoint\n",
            "220m 11s (- 0m 0s) (100 100%) 0.1011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dcnNwvZyB7WLCRsoohAgogLoDOKtNV2pj8rLrVVy2jLzHSmM60znS6/zm9+M50+fn1MrVaLe7V1mWrVWh21VkXZJMgii0CIgbAmhBASQvbv7497wRizQW5y7vJ+Ph553OV87z0fTm7efO/3fM855pxDRETCX4zXBYiISHAo0EVEIoQCXUQkQijQRUQihAJdRCRCxHq14uzsbFdYWOjV6kVEwtL69euPOOdyelrmWaAXFhZSVlbm1epFRMKSme3pbZmGXEREIoQCXUQkQijQRUQihAJdRCRCKNBFRCJEv4FuZg+bWbWZbemnXamZtZvZF4NXnoiIDNRAeuiPAov6amBmPuDHwGtBqElERM5Cv4HunFsBHO2n2V8DzwLVwSiqLzsONfBvf9jGydaOoV6ViEhYGfQYupmNA74A3DeAtkvNrMzMympqas5qffvqmnjgnY/YtO/YWb1eRCRSBWOn6H8B33HOdfbX0Dm33DlX4pwrycnp8cjVfs0uyACgrLK/Lw0iItElGIf+lwBPmRlANrDYzNqdc88H4b0/JT0pnsmjUlhXWTcUby8iErYGHejOuQmn7pvZo8BLQxXmp5QUZvL7jQfo6HT4YmwoVyUiEjYGMm3xSWA1MMXM9pnZbWZ2h5ndMfTl9ay0MIOGlnZ2HGrwqgQRkZDTbw/dObdkoG/mnPvKoKoZoJKCTADK9hxl2tiRw7FKEZGQF5ZHio7PSGT0yBEaRxcR6SIsA93MKCnMYN1HR3HOeV2OiEhICMtABygtzOTQ8Wb2HzvpdSkiIiEhbAO9pPDUfHQNu4iIQBgH+tTRI0lJiGWdDjASEQHCONB9Mcasggz10EVEAsI20AFKCzLYcbiB+qY2r0sREfFcWAd6SaF/Pvr6vRp2EREJ60C/IC+d2BjTfHQREcI80BPjfZw3Lk1nXhQRIcwDHfznddlUVU9zmy54ISLRLewDvaQwk9aOTrbsr/e6FBERT4V/oJ+64MUejaOLSHQL+0DPSkmgKCdZ4+giEvXCPtABSgsyKdtTR2enTtQlItErIgK9pDCDY01t7K5p9LoUERHPRESglwYOMNJ8dBGJZhER6AVZSWSnJGgcXUSiWkQEuplRWpjBuj0KdBGJXhER6OCfj1519CSH6pu9LkVExBMRE+ilpy54oV66iESpiAn0aWNGkhTv0/nRRSRq9RvoZvawmVWb2ZZelt9oZpvN7AMzW2VmM4JfZv9ifTHMzE/XFYxEJGoNpIf+KLCoj+UfAfOdc9OBfwWWB6Gus1JSkMn2g8dpaNYFL0Qk+vQb6M65FUCv3V7n3Crn3KlxjjXA+CDVdsZKCzPpdLBh7zGvShAR8Uywx9BvA17pbaGZLTWzMjMrq6mpCfKq4YL8dHwxpvnoIhKVghboZrYQf6B/p7c2zrnlzrkS51xJTk5OsFZ9WkpCLNPGjNQRoyISlYIS6GZ2PvAgcK1zrjYY73m2Sgoz2FBVR1tHp5dliIgMu0EHupnlA88BNzvndg6+pMEpLcykua2TrQeOe12KiMiwiu2vgZk9CSwAss1sH/ADIA7AOXc/8H0gC/iFmQG0O+dKhqrg/py+4EXlUS7IS/eqDBGRYddvoDvnlvSz/Hbg9qBVNEi5I0dQkJXEusqj3H5pkdfliIgMm4g5UrSrkoJMyirrcE4XvBCR6BGRgV5amEHtiVY+OnLC61JERIZNRAZ6SeCCFzqvi4hEk4gM9OKcZDKS4nReFxGJKhEZ6GZGSaH/wtEiItEiIgMd/OPoHx05QU1Di9eliIgMi4gN9NkF/nH09brghYhEiYgN9PPGjSQhNkbndRGRqBGxgZ4Q62NGXrrOvCgiUSNiAx384+hbDhynqbXd61JERIZcRAd6SWEmHZ2OjbrghYhEgYgO9Fn5GZihcXQRiQoRHehpiXFMGZVKmWa6iEgUiOhAB//50d/fU0e7LnghIhEu4gO9pDCDE60dfHiowetSRESGVMQHemngRF06r4uIRLqID/Sx6YmMS0/UmRdFJOJFfKCDf9hlXeVRXfBCRCJalAR6JtUNLVQdPel1KSIiQyYqAr200H/haI2ji0gki4pAn5ybSuqIWM1HF5GI1m+gm9nDZlZtZlt6WW5mdreZlZvZZjObFfwyBycmxigpyNARoyIS0QbSQ38UWNTH8quBSYGfpcB9gy8r+EoKMymvbuToiVavSxERGRL9BrpzbgXQ11jFtcCvnN8aIN3MxgSrwGA5NR99vS5LJyIRKhhj6OOAqi6P9wWe+xQzW2pmZWZWVlNTE4RVD9z549OI98Xo/OgiErGGdaeoc265c67EOVeSk5MznKtmRJyP6ePTNNNFRCJWMAJ9P5DX5fH4wHMhp6Qwgw/219Pc1uF1KSIiQReMQH8R+HJgtstcoN45dzAI7xt0pQWZtHU4NlXpghciEnli+2tgZk8CC4BsM9sH/ACIA3DO3Q+8DCwGyoEm4KtDVexgzS7wH2BUtqeOC4uyPK5GRCS4+g1059ySfpY74BtBq2gIZSTHMyk3RePoIhKRouJI0a5KCjNZv6eOzk6dqEtEIkvUBXppYQYNze28v1fz0UUkskRdoF957mjSk+K4763dXpciIhJUURfoKQmx3HrxBN74sJot++u9LkdEJGiiLtABbplXSGpCLPe+We51KSIiQROVgZ6WGMct8wp5Zcshdh7WxaNFJDJEZaAD3HrJBJLifeqli0jEiNpAz0yO56a5Bfx+0wE+OnLC63JERAYtagMd4PZLJxDni+G+t9RLF5HwF9WBnps6giVz8nnu/f1UHW3yuhwRkUGJ6kAH+Kv5RZjBL1doXrqIhLeoD/QxaYl8cXYez6zbx6H6Zq/LERE5a1Ef6ABfX1BMh3MsX1HhdSkiImdNgQ7kZSbx+QvG8Zv39nCkscXrckREzooCPeAbC4tpae/kwXc+8roUEZGzokAPKMpJ4bPnj+Xx1ZXUnWj1uhwRkTOmQO9i2cKJnGjt4JFVlV6XIiJyxhToXUwZncpV547ikZUfcby5zetyRETOiAK9m2ULJ9HQ3M7jq/d4XYqIyBlRoHczfXwaC6fk8OA7FZxoafe6HBGRAVOg92DZ5ZOoa2rjN2v3el2KiMiAKdB7MLsgg4snZrH8nQqa2zq8LkdEZEAGFOhmtsjMdphZuZnd1cPyfDN708w2mNlmM1sc/FKH17KFk6hpaOHpdVVelyIiMiD9BrqZ+YB7gauBacASM5vWrdm/AM8452YC1wO/CHahw21uUSalhRnc//ZuWts7vS5HRKRfA+mhzwHKnXMVzrlW4Cng2m5tHDAycD8NOBC8Er1hZiy7fBIH65t59v19XpcjItKvgQT6OKDruMO+wHNd/RC4ycz2AS8Df93TG5nZUjMrM7Oympqasyh3eF02KZsZ49P4xVvltHeoly4ioS1YO0WXAI8658YDi4HHzexT7+2cW+6cK3HOleTk5ARp1UPnVC+96uhJXtgY9l86RCTCDSTQ9wN5XR6PDzzX1W3AMwDOudXACCA7GAV67c/OyeWcMSO5961yOjqd1+WIiPRqIIG+DphkZhPMLB7/Ts8Xu7XZC1wBYGbn4A/00B9TGQAzY9nCiVTUnODlDw56XY6ISK/6DXTnXDuwDHgV2I5/NstWM/uRmV0TaPYt4Gtmtgl4EviKcy5iurNXnzeaibkp3POncjrVSxeREBU7kEbOuZfx7+zs+tz3u9zfBlwc3NJCR0yM8Y2Fxfzd05t4ffthrjp3tNcliYh8io4UHaDPnT+Wgqwk7vlTORH05UNEIogCfYBifTF8fUExH+yv562dEbF7QEQijAL9DHxh5njGpSfy8zd2qZcuIiFHgX4G4mNjuGN+Ee/vPcYjKyu9LkdE5BMGtFNUPrZkTj4ry2v50UvbSE7w8aXSfK9LEhEB1EM/Y7G+GO5eMpMFU3K467kPeGFj92OsRES8oUA/C/GxMdx/02wunJDJ3z+zide2HvK6JBERBfrZGhHn48FbSpk+Lo1lv9nACs18ERGPKdAHISUhlse+Oofi3BSWPl7G2opar0sSkSimQB+ktKQ4Hr9tDuPSE7ntsTI2Vh3zuiQRiVIK9CDITkng17fPJTM5nlsefo/tB497XZKIRCEFepCMThvBr2+/kKR4Hzc/tJbdNY1elyQiUUaBHkR5mUk8cfuFANz4wFqqjjZ5XJGIRBMFepAV56Tw+G0XcrKtgxseXMOh+mavSxKRKKFAHwLnjBnJr26dQ92JNm58cA1HGlu8LklEooACfYjMyEvnoVtK2H/sJDc/9B71TW1elyQiEU6BPoQuLMpi+c0l7K5u5JZH3qOxpd3rkkQkginQh9hlk3O454aZfLC/nlsfXcfJ1g6vSxKRCKVAHwZXnjuan143g3WVR7njifW0tCvURST4FOjD5NoLxvEffzGdt3fW8DdPbqCto9PrkkQkwijQh9GXSvP5weem8erWw9z2WJnG1EUkqAYU6Ga2yMx2mFm5md3VS5vrzGybmW01s98Et8zI8dWLJ/Djv5zOyvIjXL98NdUNmqcuIsHRb6CbmQ+4F7gamAYsMbNp3dpMAv4JuNg5dy7wzSGoNWJ8qTSfB748m93VJ/iLX6zSaQJEJCgG0kOfA5Q75yqcc63AU8C13dp8DbjXOVcH4JyrDm6ZkefyqaN4aulcTrZ28MX7VrF+T53XJYlImBtIoI8Dqro83hd4rqvJwGQzW2lma8xsUU9vZGZLzazMzMpqanRBiBl56Tz39XmkJcZxwwNrdOUjERmUYO0UjQUmAQuAJcADZpbevZFzbrlzrsQ5V5KTkxOkVYe3gqxknr1zHlPHjOSOJ9bz+Jo9XpckImFqIIG+H8jr8nh84Lmu9gEvOufanHMfATvxB7wMQFZKAk9+7UIWTsnle89v4SevfohzzuuyRCTMDCTQ1wGTzGyCmcUD1wMvdmvzPP7eOWaWjX8IpiKIdUa8pPhYfnnzbJbMyePeN3fzrf/epLnqInJGYvtr4JxrN7NlwKuAD3jYObfVzH4ElDnnXgwsu9LMtgEdwD8653SBzTMU64vh/35hOmPSEvnp6zupaWjhvptmk5LQ769JRATz6qt9SUmJKysr82Td4eCZdVX80+8+YOroVB75Sim5I0d4XZKIhAAzW++cK+lpmY4UDVHXlebx4C0lfHTkBF/4xSrKqzVXXUT6pkAPYQun5PLU0rm0tHfwxftXsX7PUa9LEpEQpkAPceePT+e5Oy8mIymeGx5Yy6uaqy4ivVCgh4H8rCR+e8dFnDNmJHc+sZ7HV1d6XZKIhCAFepjwz1Wfy+VTR/G9F7bynd9upqlVZ2sUkY8p0MNIYryP+2+axTcWFvPM+iquuWclHx467nVZIhIiFOhhJtYXwz9eNZUnbruQ+pNtXHvPSp5Ys0dHloqIAj1cXTwxm1f+9lLmFmXxL89v4eu/fp/6pjavyxIRDynQw1h2SgKPfKWUf148lde3HWbx3e/oNLwiUUyBHuZiYoyllxXz2zvn4Ysxrvvlau59s5zOTg3BiEQbBXqEuCAvnZf+5hKuPm80P3l1B19++D1d3k4kyijQI8jIEXH8fMlMfvyX0ynbc5TFP3uHt3fqQiIi0UKBHmHMjC+V5vP7ZZeQlZzALQ+/x7+/vJ3Wdp2KVyTSKdAj1KRRqbyw7GJuvDCfX66o4H/9cjV7a5u8LktEhpACPYKNiPPxb1+Yzn03zqKippHP3P0Ov990wOuyRGSIKNCjwNXTx/Dy31zKpFEp/PWTG7jr2c0cb9acdZFIo0CPEnmZSTz9Vxfx9QXFPF1WxYKfvMXjqytp12XuRCKGAj2KxPli+Paiqbz4jUuYlJvC917YylX/tYI3th/WqQNEIoACPQpNH5/GU0vnsvzm2TgHtz1Wxo0PrmXrgXqvSxORQVCgRykz48pzR/Pq313G/77mXLYfPM5nf/4u//DfmzhUrwOSRMKRLhItANSfbOPeN8t5dGUlvhhj6WVF/NX8IpLiY70uTUS60EWipV9piXH88+JzeONb87n8nFx+9sYuFvzkLZ5ZV0WHzgsjEhYGFOhmtsjMdphZuZnd1Ue7vzQzZ2Y9/u8hoS8vM4l7b5jFs3fOY1xGIt9+djOfufsd3t11xOvSRKQf/Qa6mfmAe4GrgWnAEjOb1kO7VOBvgbXBLlKG3+yCDJ67cx733DCTE63t3PTQWr76yHvsOtzgdWki0ouB9NDnAOXOuQrnXCvwFHBtD+3+FfgxoD1qEcLM+Oz5Y/nj38/nnxdPpWxPHYt+9g7f/d0HHDh20uvyRKSbgQT6OKCqy+N9gedOM7NZQJ5z7g99vZGZLTWzMjMrq6nRWQDDRUKsj6WXFfP2Py7k5rkFPL2uisv+803+7umNbDuga5qKhIpB7xQ1sxjgp8C3+mvrnFvunCtxzpXk5OQMdtUyzDKT4/nhNefy9rcXcsu8Ql7beojFd7/DzQ+t5Z1dNTo4ScRjAwn0/UBel8fjA8+dkgqcB7xlZpXAXOBF7RiNXOPSE/neZ6ex6p+u4DuLprLjUAM3P/Qen7n7XZ7fsJ82nU5AxBP9zkM3s1hgJ3AF/iBfB9zgnNvaS/u3gH9wzvU5yVzz0CNHS3sHL2w8wAMrKthV3ci49ES+enEh18/JJyVB89hFgmlQ89Cdc+3AMuBVYDvwjHNuq5n9yMyuCW6pEo4SYn1cV5LHq9+8jIe/UsL4jET+zx+2c9G/v8F/vPIhh49rP7nIcNCRojIkNlUdY/mKCl7ZchBfjPH5C8ax9LIiJo1K9bo0kbDWVw9dgS5Dak/tCR569yOeKauiua2Ty6fm8rVLi7hwQiYxMeZ1eSJhR4Eunjt6opUn1uzhsVWV1J5oJTM5nnnFWVw8MZtLJmaTl5nkdYkiYUGBLiGjua2D/9lyiBW7alhZfoTDx1sAyM9MOh3uFxVnkZkc73GlIqFJgS4hyTnH7ppGVpbX8m75EdbsrqWhpR0zmDZmJJdMzObiidmUFmaSGO/zulyRkKBAl7DQ3tHJ5v31rNx1hHfLj/D+3jraOhzxvhhmFaSfDvjp49KI9elEoRKdFOgSlppa21lXWcfK8iO8u+sI2w76TzOQOiKWPz9nFJ85fwyXTMomIVa9d4kefQW6jvqQkJUUH8v8yTnMn+w/TURtYwurdtfy9s4aXtt6iOc27Cd1RCxXnTuaz5w/houLs4mPVc9dopd66BKWWts7WVl+hJc2H+S1bYdoaG4nLTGOq84dxWfPH8tFxVnEaVhGIpCGXCSitbR38O4uf7i/vu0wjS3tZCTFsei80Xxm+ljmFmVqzF0ihgJdokZzWwcrdtbw0uaD/HH7YZpaO8hKjveH+/ljuHBCFj4d0CRhTIEuUam5rYO3dlTz0uaDvLG9mpNtHWSnJHD1eaO54pxc5hZlMSJOO1QlvCjQJeo1tbbz5oc1/OGDA/zpw2qa2zpJiI1hblEWC6b4d7xOyE7GTL13CW0KdJEumts6WFPhny3z9o4aKo6cAPxHq86fnMOCKTlcVJxFUrwmgUnoUaCL9GFvbRNv76zm7Z01rCyv5WRbB/G+GOZMyPRPm5ySw6TcFPXeJSQo0EUGqKW9g7LKOt7a4Q/4nYcbARibNoL5U3KYPzmXiydmkToizuNKJVop0EXO0v5jJ1mxs4a3dlSzsryWxpZ2YmOMGXnpXFSUxbziLGYVZGjnqgwbBbpIELR1dLJ+Tx0rdtawanctH+yvp6PTER8bw6z8dOYV+88UOWN8uo5YlSGjQBcZAg3NbayrPMqq8lpWV9Sy7eBxnIPEOB8lhRmnA/68sSN1YJMEjQJdZBgca2plTcVRVu8+wuqK2tPj76kJscyZkMlFxVlcVJzFOaNH6mpNctZ0ci6RYZCe5D8iddF5owGoaWhhTUUtq3bXsqailjc+rAZg5IhYslMTSIzzMSLOF7iNYUS3x4lxPhJOP/aRGB/DiFgfifE+Jo9KZUzaCM28kU9QoIsMkZzUBD43YyyfmzEWgIP1J1m9u5Z1lXUcb26jubWD5vYOmlrbOXqik+a2DprbOjjZ1kFzWyfN7R309QV61MgEZuZlcEF+OjPz0pk+Pk1z56PcgIZczGwR8DPABzzonPuPbsv/HrgdaAdqgFudc3v6ek8NuYj0zTlHS3snLW2dgZD3h31jSzvbDhxnw946NlQdY09tEwC+GGPq6FRm5qdzQV4GM/PTmZCVrOGdCDOoMXQz8wE7gT8H9gHrgCXOuW1d2iwE1jrnmszsTmCBc+5Lfb2vAl0kOGobW9i07xgb9vp/NlYdo7GlHYC0xDguyEsPhLz/Jz1J12sNZ4MdQ58DlDvnKgJv9hRwLXA60J1zb3Zpvwa46ezLFZEzkZWSwOVTR3H51FEAdHT6r9W6ce8xNlTVsWHvMe5+Yxedgb5bUU4yJQUZlBRmUlqYSWFWksbiI8RAAn0cUNXl8T7gwj7a3wa8MpiiROTs+WKMyaNSmTwqletK8wBobGln8+lefB2vbTvMM2X7AMhOiaekIJOSwgxKCzOZNnakLg4SpoK6B8XMbgJKgPm9LF8KLAXIz88P5qpFpA8pCbHMK85mXnE2AJ2djoojjayrrGNd5VHKKuv4n62HAP88+pn56YEefAYz8zNISdDO1nAwkN/SfiCvy+Pxgec+wcz+DPguMN8519LTGznnlgPLwT+GfsbVikhQxMQYE3NTmZibypI5/s7V4ePNlAUCfl3lUe75k3+YxhdjTBsz8nQPvqQgg9yRIzz+F0hPBrJTNBb/TtEr8Af5OuAG59zWLm1mAr8FFjnndg1kxdopKhLaGprb2LD3GGWVR1lXWceGqjqa2zoByEqOpygnmaLsFIpz/bdFOcnkZybpqNghNugjRc1sMfBf+KctPuyc+zcz+xFQ5px70cz+CEwHDgZestc5d01f76lAFwkvbR2dbD1wnPV76iivbmB39QkqjjRypLH1dJs4n5GfmURRTgrFOf6QLw4Ef0ayZtcEgw79F5EhU9/Uxu4jjVTUnGB3TSMVNf77lbUnaOv4OF8yk+Mpyk6mOCeFibkpTByVwqTcFMamJWqu/BnQof8iMmTSkuKYlZ/BrPyMTzzf3tHJvrqTVBxpPN2b311zgjc+PMzTZR9PnEuK9/kDPjeFSbmpTMpNYdKoFMZnJOmC3mdIgS4iQyLWF0NhdjKF2clcPvWTy+pOtFJe08iuw43sqm6gvLqRleVHeO79j+dbjIiLoTgnJRDwqYHAT9E4fR8U6CIy7DKS4ylN9h/Y1FX9yTbKqxspr24IhL1/auXzGw+cbhPvi6EoJ5lJo/y9+cmj/IFfoKBXoItI6EhLjGN2QQazCz45fNPY0s7uan/A7zrcwK7qRjbsreP3mz4d9BNzUwIHVqUwMTeVwqzoCXoFuoiEvJSEWGbkpTMjL/0Tzze1tlNe3cjOwNDNrsONbKw6xkubD55u0z3oJ+WmkJkcT1J8rP+UxHE+//04HwmxMWG9g1aBLiJhKyk+lvPHp3P++DMP+t4kxvnPOf+J2y73k+J9jM9IZMrokUwZnUJhVnLIfANQoItIxOkr6CtqTlB/so2TrR00tXXQ3Oo/LXFT4PZka3vgtpOTbe3+dq0dHGtq5WBbBydaOnh+48nTJzuL98VQnJvC1NGpTBmdypRR/lsvLkCiQBeRqJEUH8t549IG/T7NbR2UVzey41ADOw43sONQA6t31/K7DR/P0kkdEcuUUalMHp3K1NH+k6VNHZ06pKcvVqCLiJyhEXE+zhuX9qn/HOqb2gIBf/x00L+06QC/Wdt+uk1uagJfu7SIr11WFPS6FOgiIkGSlhTHnAmZzJnw8XRM5xyHjjf7e/OBHn3uyIQhWb8CXURkCJkZY9ISGZOWyIIpuUO6rtDYNSsiIoOmQBcRiRAKdBGRCKFAFxGJEAp0EZEIoUAXEYkQCnQRkQihQBcRiRCeXVPUzGqAPWf58mzgSBDLCbZQrw9Cv0bVNziqb3BCub4C51xOTws8C/TBMLOy3i6SGgpCvT4I/RpV3+CovsEJ9fp6oyEXEZEIoUAXEYkQ4Rroy70uoB+hXh+Efo2qb3BU3+CEen09CssxdBER+bRw7aGLiEg3CnQRkQgR0oFuZovMbIeZlZvZXT0sTzCzpwPL15pZ4TDWlmdmb5rZNjPbamZ/20ObBWZWb2YbAz/fH676AuuvNLMPAusu62G5mdndge232cxmDWNtU7psl41mdtzMvtmtzbBvPzN72MyqzWxLl+cyzex1M9sVuM3o5bW3BNrsMrNbhrG+n5jZh4Hf4e/MLL2X1/b5eRjC+n5oZvu7/B4X9/LaPv/eh7C+p7vUVmlmG3t57ZBvv0FzzoXkD+ADdgNFQDywCZjWrc3XgfsD968Hnh7G+sYAswL3U4GdPdS3AHjJw21YCWT3sXwx8ApgwFxgrYe/60P4D5jwdPsBlwGzgC1dnvtP4K7A/buAH/fwukygInCbEbifMUz1XQnEBu7/uKf6BvJ5GML6fgj8wwA+A33+vQ9Vfd2W/z/g+15tv8H+hHIPfQ5Q7pyrcM61Ak8B13Zrcy3wWOD+b4ErzMyGozjn3EHn3PuB+w3AdmDccKw7iK4FfuX81gDpZjbGgzquAHY75872yOGgcc6tAI52e7rr5+wx4PM9vPQq4HXn3FHnXB3wOrBoOOpzzr3mnDt1FeI1wPhgr3egetl+AzGQv/dB66u+QHZcBzwZ7PUOl1AO9HFAVZfH+/h0YJ5uE/hA1wNZw1JdF4GhnpnA2h4WX2Rmm8zsFTM7d1gLAwe8ZmbrzWxpD8sHso2Hw/X0/kfk5fY7ZZRz7mDg/iFgVA9tQmVb3or/W1dP+vs8DKVlgSGhh3sZsgqF7XcpcNg5t6uX5V5uvwEJ5UAPC2aWAjwLfNM5d7zb4vfxDyPMAH4OPD/M5V3inJsFXA18w8wuG+b190yLPD4AAAJLSURBVMvM4oFrgP/uYbHX2+9TnP+7d0jO9TWz7wLtwK97aeLV5+E+oBi4ADiIf1gjFC2h7955yP89hXKg7wfyujweH3iuxzZmFgukAbXDUp1/nXH4w/zXzrnnui93zh13zjUG7r8MxJlZ9nDV55zbH7itBn6H/2ttVwPZxkPtauB959zh7gu83n5dHD41FBW4re6hjafb0sy+AnwWuDHwn86nDODzMCScc4edcx3OuU7ggV7W6/X2iwX+Ani6tzZebb8zEcqBvg6YZGYTAr2464EXu7V5ETg1m+CLwJ96+zAHW2C87SFgu3Pup720GX1qTN/M5uDf3sPyH46ZJZtZ6qn7+HecbenW7EXgy4HZLnOB+i5DC8Ol116Rl9uvm66fs1uAF3po8ypwpZllBIYUrgw8N+TMbBHwbeAa51xTL20G8nkYqvq67pf5Qi/rHcjf+1D6M+BD59y+nhZ6uf3OiNd7Zfv6wT8LYyf+vd/fDTz3I/wfXIAR+L+qlwPvAUXDWNsl+L96bwY2Bn4WA3cAdwTaLAO24t9jvwaYN4z1FQXWuylQw6nt17U+A+4NbN8PgJJh/v0m4w/otC7Pebr98P/nchBowz+Oexv+/TJvALuAPwKZgbYlwINdXntr4LNYDnx1GOsrxz/+fOpzeGrm11jg5b4+D8NU3+OBz9dm/CE9pnt9gcef+nsfjvoCzz966nPXpe2wb7/B/ujQfxGRCBHKQy4iInIGFOgiIhFCgS4iEiEU6CIiEUKBLiISIRToIiIRQoEuIhIh/j/UJuFPEH2fTwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}