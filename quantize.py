"""
Quantization according to music21's default.

By default, music21 will generate a lowest common denominator quantization for 
music that was generated by a program, e.g. NOT a live recording.

Example: Note/Chord/Rest            Duration                            Offset
Piano	<music21.duration.Duration 0.0>                                 0.0
<music21.chord.Chord C5 E5 G5 C6>	<music21.duration.Duration 1.25>	0.0
<music21.chord.Chord B4 D5 G5 D6>	<music21.duration.Duration 13/12>	1.25
<music21.chord.Chord B4 C5 D5 G5 D6 E6>	<music21.duration.Duration 1/6>	7/3
<music21.chord.Chord C5 G5 E6>	<music21.duration.Duration 13/12>	    2.5
<music21.chord.Chord C5 G5>	<music21.duration.Duration 1/12>	        43/12

PS: Piano is the instrument, not a chord or note. 

The default common time step is therefore the largest denominator. In the example, 
that's 1/12. This means the smallest resolution of the piece is at 1/12. If the 
piece is using 4/4 time signature, this means there are 48 quanta per measure.

In this data set, everything is treated in 4/4 time signature.

The textual representation of a piece is the following:

>>> cat example.txt
quantum 12 // 12 quanta per beat; there are no comments in the real data

B-3 3/2 // B flat third octave, 1.5 beats or 18 quanta long
xxsep 12 // advance through time by 12 quanta
C4 5/4 // standard C, 1.25 beats or 15 quanta long
D2 5/4 // D second octave, 1.25 beats or 15 quanta long, this forms a chord with C4
xxsep 2 // advance through time by 2 quanta
Rest 1 // rest, 1 beat or 12 quanta long

"""
# --------------------
from itertools import zip_longest
from typing import List
from fractions import Fraction
import numpy as np

from music21 import converter
from music21.stream import Score
from music21.chord import Chord
from music21.note import Note, Rest

def readMIDI(path: str) -> Score:
    """Read a midi file into a music21.Score object

    Args:
        path (str): Path to the midi file

    Returns:
        Score: music21.Score object
    """
    return converter.parse(path)

def scoreToText(score: Score, force_quantum=None) -> List[str]:
    """Converts a score into a list of string tokens

    Args:
        score (Score): music21.Score object
        force_quantum (int): By default, inactivated. If an int is given,
        the method will squeeze the notes and rests into the closest quantum.
        The int is the number of quanta per beat. Default depends on the midi file.

    Returns:
        List[str]: List of tokens
    """
    tokens: List[str] = []

    if force_quantum is not None:
        raise NotImplementedError

    # "chordify" the score: all voices and parallel parts turn into one
    chords = score.chordify()

    # find the quantum duration
    durations : List[Fraction] = []
    offsets : List[Fraction] = []
    for chord in chords.notesAndRests:
        durations.append(Fraction(chord.quarterLength).limit_denominator(100))
        offsets.append(Fraction(chord.offset).limit_denominator(100))

    # usually it is 12
    quantum_duration = np.lcm(
        max((d.denominator for d in durations)),
        max((o.denominator for o in offsets)) 
    )

    # take the derivative of offsets, to get the rate of change in quanta/note
    offset_rates : List[Fraction] = np.diff(offsets)

    assert len(offset_rates) == len(durations) - 1

    # lead token stream with metadata
    tokens.append("quantum")
    tokens.append(str(quantum_duration))

    # score starts here
    for chord, duration, offset in zip_longest(chords.notesAndRests, durations, offset_rates):
        
        # get note, chord, rest info
        if type(chord) is Chord:
            tokens.extend(chordToTokens(chord))
        elif type(chord) is Note:
            tokens.extend(noteToTokens(chord))
        elif type(chord) is Rest:
            tokens.append("Rest")
            tokens.append(str(duration))
        else:
            raise TypeError("Unknow type to turn to tokens {t}".format(t=type(chord)))

        # xxsep tokens
        if offset is not None:
            tokens.append("xxsep")
            tokens.append(str(offset.numerator))

    return tokens

def chordToTokens(chord: Chord) -> List[str]:
    """Turns a chord into textual tokens

    Args:
        chord (Chord): music21 chord

    Returns:
        List[str]: List of text tokens
    """
    tokens : List[str] = []

    for note in chord.notes:
        tokens.extend(noteToTokens(note))

    return tokens

def noteToTokens(note: Note) -> List[str]:
    """Converts a note into textual tokens

    Args:
        note (Note): music21 Note

    Returns:
        List[str]: List of textual tokens
    """
    tokens : List[str] = []

    tokens.append(note.pitch.nameWithOctave)
    tokens.append(str(Fraction(note.duration.quarterLength).limit_denominator(100)))

    return tokens

def main():
    s = readMIDI("data/JSB Chorales/test/102.mid")

    print(scoreToText(s))

    
if __name__ == "__main__":
    main()